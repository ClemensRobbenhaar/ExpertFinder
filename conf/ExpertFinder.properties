# the language in which the wiki's content is written
language = de

# the type of the wiki (currently, only MediaWiki is supported)
wiki.type = MediaWiki

# the URL of the wiki's web API
#wiki.mediawiki.api = http://wiki.eclipse.org/api.php
wiki.mediawiki.api = http://localhost/eclipsewiki/api.php

# the URL of the wiki's ajax interface
#wiki.mediawiki.ajax = http://wiki.eclipse.org/index.php?action=ajax
wiki.mediawiki.ajax = http://localhost/eclipsewiki/index.php?action=ajax

# classpath relative path to the domain ontology
ontology.file = /ontology/SEOntology.owl

# URI of the root concept in the ontology 
ontology.baseconceptURI = http://www.owl-ontologies.com/unnamed.owl#Domain_Vocabulary

# URI of the base concept of the domain sub model in the ontology - unused
### ontology.domain.baseconceptURI = http://www.ag-csw.de/ontologies/expertfinder#Eclipse_Project_Domain_Vocabulary

# URI of the base concept of the problem sub model in the ontology - unused
### ontology.problem.baseconceptURI = http://www.ag-csw.de/ontologies/expertfinder#Eclipse_Project_Problem_Vocabulary

# Similarity measure for calculating concept similarity.
# Possible values are (uncomment one):
#
# ontology.similarity.measure = simpack.measure.graph.ScaledShortestPath
# ontology.similarity.measure = simpack.measure.graph.ShortestPath
# ontology.similarity.measure = simpack.measure.it.JiangConrath
# ontology.similarity.measure = simpack.measure.it.Lin
# ontology.similarity.measure = simpack.measure.it.Resnik
# ontology.similarity.measure = simpack.measure.it.JensenShannon
ontology.similarity.measure = simpack.measure.graph.ConceptualSimilarity

# The minimum similarity between two topic classes such that they are still deemed
# similar.
ontology.minTopicSimilarity = .5

# The weighting for the creation of a topic (document, section, or category)
# in the expertise calculation
expertise.weight.topic_creation = 3

# The weighting for the creation of a term matching a domain relevant topic.
expertise.weight.word_topic_match = 1

# The weighting for a single unit of contribution for an existing topic,
# depending on the depth of the topic
expertise.weight.category_contribution = 5
expertise.weight.document_contribution = 5
expertise.weight.section_1_contribution = 5
expertise.weight.section_2_contribution = 5
expertise.weight.section_3_contribution = 5
expertise.weight.section_4_contribution = 5
expertise.weight.section_5_contribution = 5
expertise.weight.section_6_contribution = 5

# The maximum expected term number of compound terms (e.g. "Software Engineering Group" has 3 terms).
# Has an impact on performance during concept matching, do not set to a value too high! (5 is okay).
ontology.index.compoundterms.maxlength = 5

# The value c > 1 in the term 1-c^(-x), determining the rate by which authors gain credibility
# when their contributions sustain a revision.
credibility.base = 1.4

# Classpath relative path to a stop word list (stop words in this file should match the language specified by the 'language' property).
# The list should be a text file, containing one stop word per line. 
analyzer.stopwords.filepath = /wordlists/stopWords_de

# For testing. If set to true, concept matching is performed on the entire text, rather than only on category, document, and section titles.
# Setting this value to true has a significant negative impact on overall performance. 
analyzer.tagallwords = false

# Classpath relative path to the wordnet dictionary (currently not used)
wordnet.dictionaryDir = /resources/wordNet

# base url for the rest server
rest.server.baseUrl=http://localhost:9090/expertfinder/
